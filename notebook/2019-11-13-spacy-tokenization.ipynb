{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tokenizer import CommitBucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from string import punctuation\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import re\n",
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = CommitBucket(\"../tmp/plotly@plotly.py.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@ -87,6 +87,14 @@ class plotly:\n",
      " \t\t\t\tpass\n",
      " \t\treturn res\n",
      " \n",
      "+\tdef fig2plotly(self, fig):\n",
      "+\t\ttry:\n",
      "+\t\t\timport matplotlylib\n",
      "+\t\texcept as e:\n",
      "+\t\t\tprint(\"Uh oh! matplotlylib not installed. Install with pip (depends on matplotlib):\\n$ sudo pip install matplotlylib\")\n",
      "+\t\t\traise e\n",
      "+\t\tmatplotlylib.fig2plotly(fig, username=self.username, key=self.api_key)\n",
      "+\n",
      " \tdef __callplot(self, *args, **kwargs):\n",
      " \t\t''' Make a plot in plotly.\n",
      " \t\tTwo interfaces:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "commits = (bucket.iterate_commits())\n",
    "diff = [next(commits) for i in range(100)][32].modifications[0].diff\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@@ -87,6 +87,14 @@ class plotly:\\n \\t\\t\\t\\tpass\\n \\t\\treturn res\\n \\n+\\tdef fig2plotly(self, fig):\\n+\\t\\ttry:\\n+\\t\\t\\timport matplotlylib\\n+\\t\\texcept as e:\\n+\\t\\t\\tprint(\"Uh oh! matplotlylib not installed. Install with pip (depends on matplotlib):\\\\n$ sudo pip install matplotlylib\")\\n+\\t\\t\\traise e\\n+\\t\\tmatplotlylib.fig2plotly(fig, username=self.username, key=self.api_key)\\n+\\n \\tdef __callplot(self, *args, **kwargs):\\n \\t\\t\\'\\'\\' Make a plot in plotly.\\n \\t\\tTwo interfaces:\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_custom_tokenizer(nlp):\n",
    "\n",
    "    token_match = re.compile(r\"(<ADD>|<DEL>|<space>|<tab>)\")\n",
    "\n",
    "    prefix_re = re.compile(r\"[(]\")\n",
    "    infix_re = re.compile(r\"[^\\w]\")\n",
    "    suffix_re = re.compile(r\"[)]\")\n",
    "    \n",
    "    return Tokenizer(nlp.vocab, \n",
    "                    None,\n",
    "                     prefix_search = prefix_re.search, \n",
    "                     infix_finditer = infix_re.finditer, \n",
    "                     suffix_search = None,\n",
    "                     token_match=token_match.search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.tokenizer = create_custom_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(,\n",
       " for,\n",
       " tok,\n",
       " in,\n",
       " https,\n",
       " :,\n",
       " /,\n",
       " /,\n",
       " google,\n",
       " .,\n",
       " com,\n",
       " r,\n",
       " a,\n",
       " n,\n",
       " g,\n",
       " e,\n",
       " (,\n",
       " 100,\n",
       " ),\n",
       " :,\n",
       " return,\n",
       " tok,\n",
       " )]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token for token in nlp(\"(for tok in https://google.com range(100): return tok)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing \n",
    "import string\n",
    "\n",
    "class PunctTokenizer:\n",
    "    def __init__(self, punctuation: str = string.punctuation, ignore_punctuation: bool = False):\n",
    "        self.punctuation = punctuation\n",
    "        self._punctuation_tokens = list(punctuation) + [\"\\n\", \"\\t\", \" \"]\n",
    "        self.ignore_punctuation = ignore_punctuation\n",
    "        self.add_token = \"<ADD>\"\n",
    "        self.del_token = \"<DEL>\"\n",
    "        self.space_token = \"<SPACE>\"\n",
    "        self.tab_token = \"<TAB>\"\n",
    "        self.new_line_token = \"<NL>\"\n",
    "    \n",
    "    def tokenize(self, text: str) -> typing.List[str]:\n",
    "        text = self.preprocess(text)\n",
    "        tokens = []\n",
    "        identation_found = False\n",
    "\n",
    "        for token in nlp(text):\n",
    "            if self.ignore_punctuation:\n",
    "                if not self.is_punctuation(token.text):\n",
    "                    tokens.append(token.text)\n",
    "                continue\n",
    "                \n",
    "            if identation_found:\n",
    "                if token.text == \" \":\n",
    "                    tokens.append(self.space_token)\n",
    "                elif token.text == \"\\t\":\n",
    "                    tokens.append(self.tab_token)\n",
    "                elif token.text == \"\\n\":\n",
    "                    tokens.append(self.new_line_token)\n",
    "                else:\n",
    "                    tokens.append(token.text)\n",
    "                    identation_found = False\n",
    "            else:\n",
    "                if token.text == \"\\n\":\n",
    "                    tokens.append(self.new_line_token)\n",
    "                    identation_found = True\n",
    "                elif token.text not in [\" \", \"\\t\"]:\n",
    "                    tokens.append(token.text)\n",
    "\n",
    "        return tokens\n",
    "    \n",
    "    def preprocess(self, text: str) -> str:\n",
    "        text = re.sub(r\"\\@@.*?\\@@\", \"\", text)\n",
    "        text = re.sub(f\"([{punctuation}\\\\\\])\", r\" \\1 \", text)\n",
    "        text = text.replace(\"\\n +\", f\"\\n{self.add_token}\").replace(\"\\n -\", f\"\\n{self.del_token}\")\n",
    "        return text\n",
    "    \n",
    "    def is_punctuation(self, token: str) -> bool:\n",
    "        return token in self._punctuation_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' class plotly : \\n \\t\\t\\t\\tpass\\n \\t\\treturn res\\n \\n<ADD> \\tdef fig2plotly ( self ,  fig )  : \\n<ADD> \\t\\ttry : \\n<ADD> \\t\\t\\timport matplotlylib\\n<ADD> \\t\\texcept as e : \\n<ADD> \\t\\t\\tprint (  \" Uh oh !  matplotlylib not installed .  Install with pip  ( depends on matplotlib )  :  \\\\ n $  sudo pip install matplotlylib \"  ) \\n<ADD> \\t\\t\\traise e\\n<ADD> \\t\\tmatplotlylib . fig2plotly ( fig ,  username = self . username ,  key = self . api _ key ) \\n<ADD> \\n \\tdef  _  _ callplot ( self ,   * args ,   *  * kwargs )  : \\n \\t\\t \\'  \\'  \\'  Make a plot in plotly . \\n \\t\\tTwo interfaces : \\n'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PunctTokenizer().preprocess(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PunctTokenizer(ignore_punctuation=True).tokenize(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [],
   "source": [
    "subword_toks = \"\"\"@@ -@@ 174,1@@ 0 +@@ 174,1@@ 1 @@ de@@ f de@@ pend@@ a@@ n@@ c@@ ies@@ _@@ in@@ _@@ d@@ o@@ t@@ _@@ f@@ or@@ m@@ at@@ (@@ p@@ at@@ h@@ )@@ :\\n f@@ o@@ r (k, k2@@ ) i@@ n t@@ w@@ o@@ _@@ w@@ a@@ y@@ s@@ :\\n l.append(\"\\\\t\\\\\"@@ %s@@ \\\\\" -@@ > \\\\\"@@ %s\\\\\"@@ ;@@ \" % (k, k2@@ )@@ )\\n \\n@@ - l.append(\"\\\\t\")\\n@@ - l.append(\"\\\\tedge [color=black];\")\\n@@ - l.append(\"\\\\tnode [shape=plaintext];\")\\n@@ - l.append(\"\\\\t\\\\\"Categories\\\\\" [label=\\\\\"@@ Categories@@ :@@ \\\\\\\\n@@ \\\\\\\\n@@ %s\\\\\"];\" % \"\\\\\\\\n\".join(category_list)@@ )\\n@@ + i@@ f category_list@@ :@@ \\n@@ + l.append(\"\\\\t\")\\n@@ + l.append(\"\\\\tedge [color=black];\")\\n@@ + l.append(\"\\\\tnode [shape=plaintext];\")\\n@@ + l.append(\"\\\\t\\\\\"Categories\\\\\" [label=\\\\\"@@ %s\\\\\"];\" % \"\\\\\\\\n\".join(category_list)@@ )\\n \\n l.append(@@ \"@@ }@@ \\\\n\"@@ )\\n r@@ e@@ t@@ u@@ r@@ n \\'@@ \\\\n@@ \\'@@ .join(@@ l@@ )\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 1091,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subword_toks.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# train sentencepiece model from `botchan.txt` and makes `m.model` and `m.vocab`\n",
    "# `m.vocab` is just a reference. not used in the segmentation.\n",
    "# spm.SentencePieceTrainer.train('--input=/workspace/tmp/openshift@openshift-ansible.jsonl --model_prefix=sentpiece --vocab_size=8000 --character_coverage=1.0 --model_type=bpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.88 s, sys: 110 ms, total: 1.99 s\n",
      "Wall time: 2.07 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "spm.SentencePieceTrainer.train('--input=/workspace/tmp/diffs.train --user_defined_symbols=<FILE>,<CHUNK>,<NL>,<ADD>,<DEL>,<URL> --model_prefix=model1 --vocab_size=16000 --hard_vocab_limit=false --input_sentence_size=1000 --model_type=bpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs = open(\"/workspace/tmp/diffs.train\").readlines()\n",
    "len(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<FILE> tutorial_02.rst <CHUNK> url this view will respond to: <NL>   <NL>  .. code-block:: python <NL>   <NL> <ADD>     from django.conf.urls import patterns, url <NL> <ADD>     from oauth2_provider import views <NL> <ADD>     from django.conf import settings <NL>      from .views import apiendpoint <NL>   <NL>      urlpatterns = patterns( <NL>          \\'\\', <NL>          url(r\\'^admin/\\', include(admin.site.urls)), <NL> <DEL>         url(r\\'^o/\\', include(\\'oauth2_provider.urls\\', namespace=\\'oauth2_provider\\')),  # look ma, i\\'m a provider! <NL> <DEL>         url(r\\'^api/hello\\', apiendpoint.as_view()),  # and also a resource server! <NL> <ADD>  <NL> <ADD>         # oauth2 provider endpoints <NL> <ADD>         url(r\\'^o/authorize/$\\', views.authorizationview.as_view(), name=\"authorize\"), <NL> <ADD>         url(r\\'^o/token/$\\', views.tokenview.as_view(), name=\"token\"), <NL> <ADD>         url(r\\'^o/revoke-token/$\\', views.revoketokenview.as_view(), name=\"revoke-token\"), <NL> <ADD>  <NL> <ADD>         url(r\\'^api/hello\\', apiendpoint.as_view()),  # a resource endpoint <NL>      ) <NL>   <NL> <ADD>     if settings.debug: <NL> <ADD>         # oauth2 application management views <NL> <ADD>  <NL> <ADD>         urlpatterns += patterns( <NL> <ADD>             \\'\\', <NL> <ADD>             url(r\\'^o/applications/$\\', views.applicationlist.as_view(), name=\"application-list\"), <NL> <ADD>             url(r\\'^o/applications/register/$\\', views.applicationregistration.as_view(), name=\"application-register\"), <NL> <ADD>             url(r\\'^o/applications/(?p<pk>\\\\d+)/$\\', views.applicationdetail.as_view(), name=\"application-detail\"), <NL> <ADD>             url(r\\'^o/applications/(?p<pk>\\\\d+)/delete/$\\', views.applicationdelete.as_view(), name=\"application-delete\"), <NL> <ADD>             url(r\\'^o/applications/(?p<pk>\\\\d+)/update/$\\', views.applicationupdate.as_view(), name=\"application-update\"), <NL> <ADD>         ) <NL> <ADD>  <NL> <ADD> you will probably want to write your own application views to deal with permissions and access control but the ones packaged with the library can get you started when developing the app. <NL> <ADD>  <NL>  since we inherit from `protectedresourceview`, we\\'re done and our api is oauth2 protected - for the sake of the lazy <NL>  programmer. <NL>   <NL> \\n',\n",
       " 441)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = diffs[9111]\n",
    "diff, len(diff.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', '<FILE>', '▁tutorial', '_02.', 'rst', '▁', '<CHUNK>', '▁url', '▁this', '▁view', '▁will', '▁respon', 'd', '▁to', ':', '▁', '<NL>', '▁', '<NL>', '▁..', '▁code', '-', 'block', '::', '▁python', '▁', '<NL>', '▁', '<NL>', '▁', '<ADD>', '▁from', '▁django', '.', 'conf', '.', 'urls', '▁import', '▁patterns', ',', '▁url', '▁', '<NL>', '▁', '<ADD>', '▁from', '▁oauth', '2_', 'provider', '▁import', '▁views', '▁', '<NL>', '▁', '<ADD>', '▁from', '▁django', '.', 'conf', '▁import', '▁settings', '▁', '<NL>', '▁from', '▁.', 'views', '▁import', '▁api', 'endpoint', '▁', '<NL>', '▁', '<NL>', '▁urlpatterns', '▁=', '▁patterns', '(', '▁', '<NL>', \"▁'',\", '▁', '<NL>', '▁url', '(', 'r', \"'\", '^', 'admin', \"/',\", '▁include', '(', 'admin', '.', 'site', '.', 'urls', ')),', '▁', '<NL>', '▁', '<DEL>', '▁url', '(', 'r', \"'\", '^', 'o', \"/',\", '▁include', \"('\", 'oauth', '2_', 'provider', '.', 'urls', \"',\", '▁namespace', \"='\", 'oauth', '2_', 'provider', \"')),\", '▁#', '▁look', '▁ma', ',', '▁i', \"'\", 'm', '▁a', '▁provider', '!', '▁', '<NL>', '▁', '<DEL>', '▁url', '(', 'r', \"'\", '^', 'api', '/', 'hello', \"',\", '▁api', 'endpoint', '.', 'as', '_', 'view', '()),', '▁#', '▁and', '▁also', '▁a', '▁resource', '▁server', '!', '▁', '<NL>', '▁', '<ADD>', '▁', '<NL>', '▁', '<ADD>', '▁#', '▁oauth', '2', '▁provider', '▁endpoints', '▁', '<NL>', '▁', '<ADD>', '▁url', '(', 'r', \"'\", '^', 'o', '/', 'authorize', \"/$',\", '▁views', '.', 'authorization', 'view', '.', 'as', '_', 'view', '(),', '▁name', '=\"', 'authorize', '\"),', '▁', '<NL>', '▁', '<ADD>', '▁url', '(', 'r', \"'\", '^', 'o', '/', 'token', \"/$',\", '▁views', '.', 'tokenview', '.', 'as', '_', 'view', '(),', '▁name', '=\"', 'token', '\"),', '▁', '<NL>', '▁', '<ADD>', '▁url', '(', 'r', \"'\", '^', 'o', '/', 'revoke', '-', 'token', \"/$',\", '▁views', '.', 'revoke', 'tokenview', '.', 'as', '_', 'view', '(),', '▁name', '=\"', 'revoke', '-', 'token', '\"),', '▁', '<NL>', '▁', '<ADD>', '▁', '<NL>', '▁', '<ADD>', '▁url', '(', 'r', \"'\", '^', 'api', '/', 'hello', \"',\", '▁api', 'endpoint', '.', 'as', '_', 'view', '()),', '▁#', '▁a', '▁resource', '▁endpoint', '▁', '<NL>', '▁)', '▁', '<NL>', '▁', '<NL>', '▁', '<ADD>', '▁if', '▁settings', '.', 'debug', ':', '▁', '<NL>', '▁', '<ADD>', '▁#', '▁oauth', '2', '▁application', '▁management', '▁views', '▁', '<NL>', '▁', '<ADD>', '▁', '<NL>', '▁', '<ADD>', '▁urlpatterns', '▁+=', '▁patterns', '(', '▁', '<NL>', '▁', '<ADD>', \"▁'',\", '▁', '<NL>', '▁', '<ADD>', '▁url', '(', 'r', \"'\", '^', 'o', '/', 'applications', \"/$',\", '▁views', '.', 'application', 'list', '.', 'as', '_', 'view', '(),', '▁name', '=\"', 'application', '-', 'list', '\"),', '▁', '<NL>', '▁', '<ADD>', '▁url', '(', 'r', \"'\", '^', 'o', '/', 'applications', '/', 'register', \"/$',\", '▁views', '.', 'application', 'registration', '.', 'as', '_', 'view', '(),', '▁name', '=\"', 'application', '-', 'register', '\"),', '▁', '<NL>', '▁', '<ADD>', '▁url', '(', 'r', \"'\", '^', 'o', '/', 'applications', '/(', '?', 'p', '<', 'pk', '>\\\\', 'd', '+', ')', \"/$',\", '▁views', '.', 'application', 'detail', '.', 'as', '_', 'view', '(),', '▁name', '=\"', 'application', '-', 'detail', '\"),', '▁', '<NL>', '▁', '<ADD>', '▁url', '(', 'r', \"'\", '^', 'o', '/', 'applications', '/(', '?', 'p', '<', 'pk', '>\\\\', 'd', '+', ')/', 'delete', \"/$',\", '▁views', '.', 'application', 'delete', '.', 'as', '_', 'view', '(),', '▁name', '=\"', 'application', '-', 'delete', '\"),', '▁', '<NL>', '▁', '<ADD>', '▁url', '(', 'r', \"'\", '^', 'o', '/', 'applications', '/(', '?', 'p', '<', 'pk', '>\\\\', 'd', '+', ')/', 'update', \"/$',\", '▁views', '.', 'application', 'update', '.', 'as', '_', 'view', '(),', '▁name', '=\"', 'application', '-', 'update', '\"),', '▁', '<NL>', '▁', '<ADD>', '▁)', '▁', '<NL>', '▁', '<ADD>', '▁', '<NL>', '▁', '<ADD>', '▁you', '▁will', '▁probably', '▁want', '▁to', '▁write', '▁your', '▁own', '▁application', '▁views', '▁to', '▁deal', '▁with', '▁permissions', '▁and', '▁access', '▁control', '▁but', '▁the', '▁ones', '▁package', 'd', '▁with', '▁the', '▁library', '▁can', '▁get', '▁you', '▁started', '▁when', '▁develop', 'ing', '▁the', '▁app', '.', '▁', '<NL>', '▁', '<ADD>', '▁', '<NL>', '▁since', '▁we', '▁inherit', '▁from', '▁`', 'protected', 'resourceview', '`,', '▁we', \"'\", 're', '▁done', '▁and', '▁our', '▁api', '▁is', '▁oauth', '2', '▁protected', '▁-', '▁for', '▁the', '▁s', 'a', 'ke', '▁of', '▁the', '▁lazy', '▁', '<NL>', '▁program', 'mer', '.', '▁', '<NL>', '▁', '<NL>']\n",
      "[15934, 3, 2684, 15033, 546, 15934, 4, 280, 310, 364, 556, 6945, 15944, 81, 15961, 15934, 5, 15934, 5, 625, 876, 15962, 593, 660, 505, 15934, 5, 15934, 5, 15934, 6, 92, 111, 15950, 1260, 15950, 1045, 88, 1707, 15958, 280, 15934, 5, 15934, 6, 92, 836, 818, 1092, 88, 863, 15934, 5, 15934, 6, 92, 111, 15950, 1260, 88, 851, 15934, 5, 92, 305, 826, 88, 477, 8177, 15934, 5, 15934, 5, 2044, 28, 1707, 15956, 15934, 5, 3315, 15934, 5, 280, 15956, 15938, 15954, 0, 418, 1955, 653, 15956, 418, 15950, 1032, 15950, 1045, 2287, 15934, 5, 15934, 7, 280, 15956, 15938, 15954, 0, 15940, 1955, 653, 115, 849, 818, 1092, 15950, 1045, 84, 2528, 341, 849, 818, 1092, 3141, 99, 2018, 332, 15958, 24, 15954, 15947, 34, 3735, 15998, 15934, 5, 15934, 7, 280, 15956, 15938, 15954, 0, 439, 15974, 4019, 84, 477, 8177, 15950, 165, 15951, 156, 2292, 99, 173, 792, 34, 1735, 1266, 15998, 15934, 5, 15934, 6, 15934, 5, 15934, 6, 99, 836, 15977, 3735, 7136, 15934, 5, 15934, 6, 280, 15956, 15938, 15954, 0, 15940, 15974, 5031, 3027, 863, 15950, 1372, 156, 15950, 165, 15951, 156, 976, 412, 155, 5031, 1075, 15934, 5, 15934, 6, 280, 15956, 15938, 15954, 0, 15940, 15974, 500, 3027, 863, 15950, 5533, 15950, 165, 15951, 156, 976, 412, 155, 500, 1075, 15934, 5, 15934, 6, 280, 15956, 15938, 15954, 0, 15940, 15974, 9565, 15962, 500, 3027, 863, 15950, 9565, 5533, 15950, 165, 15951, 156, 976, 412, 155, 9565, 15962, 500, 1075, 15934, 5, 15934, 6, 15934, 5, 15934, 6, 280, 15956, 15938, 15954, 0, 439, 15974, 4019, 84, 477, 8177, 15950, 165, 15951, 156, 2292, 99, 34, 1735, 2329, 15934, 5, 532, 15934, 5, 15934, 5, 15934, 6, 124, 851, 15950, 2927, 15961, 15934, 5, 15934, 6, 99, 836, 15977, 854, 4737, 863, 15934, 5, 15934, 6, 15934, 5, 15934, 6, 2044, 2465, 1707, 15956, 15934, 5, 15934, 6, 3315, 15934, 5, 15934, 6, 280, 15956, 15938, 15954, 0, 15940, 15974, 2883, 3027, 863, 15950, 950, 296, 15950, 165, 15951, 156, 976, 412, 155, 950, 15962, 296, 1075, 15934, 5, 15934, 6, 280, 15956, 15938, 15954, 0, 15940, 15974, 2883, 15974, 1001, 3027, 863, 15950, 950, 7198, 15950, 165, 15951, 156, 976, 412, 155, 950, 15962, 1001, 1075, 15934, 5, 15934, 6, 280, 15956, 15938, 15954, 0, 15940, 15974, 2883, 10309, 0, 15946, 15984, 898, 3764, 15944, 15995, 15957, 3027, 863, 15950, 950, 827, 15950, 165, 15951, 156, 976, 412, 155, 950, 15962, 827, 1075, 15934, 5, 15934, 6, 280, 15956, 15938, 15954, 0, 15940, 15974, 2883, 10309, 0, 15946, 15984, 898, 3764, 15944, 15995, 4769, 990, 3027, 863, 15950, 950, 990, 15950, 165, 15951, 156, 976, 412, 155, 950, 15962, 990, 1075, 15934, 5, 15934, 6, 280, 15956, 15938, 15954, 0, 15940, 15974, 2883, 10309, 0, 15946, 15984, 898, 3764, 15944, 15995, 4769, 649, 3027, 863, 15950, 950, 649, 15950, 165, 15951, 156, 976, 412, 155, 950, 15962, 649, 1075, 15934, 5, 15934, 6, 532, 15934, 5, 15934, 6, 15934, 5, 15934, 6, 328, 556, 4397, 1223, 81, 1938, 623, 1967, 854, 863, 81, 7854, 325, 1299, 173, 1446, 2444, 842, 58, 14036, 1074, 15944, 325, 58, 2520, 393, 250, 328, 6103, 850, 1647, 52, 58, 362, 15950, 15934, 5, 15934, 6, 15934, 5, 3360, 429, 4367, 92, 146, 2986, 5112, 1874, 429, 15954, 10, 4296, 173, 939, 477, 153, 836, 15977, 4139, 196, 107, 58, 41, 15939, 179, 198, 58, 5923, 15934, 5, 8251, 2805, 15950, 15934, 5, 15934, 5]\n"
     ]
    }
   ],
   "source": [
    "# makes segmenter instance and loads the model file (m.model)\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('model1.model')\n",
    "\n",
    "# encode: text => id\n",
    "print(sp.encode_as_pieces(diff))\n",
    "print(sp.encode_as_ids(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sp.encode_as_pieces(diff))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
